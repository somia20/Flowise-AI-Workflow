{
  "nodes": [
    {
      "id": "seqStart_0",
      "position": {
        "x": 535.1559788923448,
        "y": 183.18440211076552
      },
      "type": "customNode",
      "data": {
        "id": "seqStart_0",
        "label": "Start",
        "version": 2,
        "name": "seqStart",
        "type": "Start",
        "baseClasses": [
          "Start"
        ],
        "category": "Sequential Agents",
        "description": "Starting point of the conversation",
        "inputParams": [],
        "inputAnchors": [
          {
            "label": "Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat",
            "id": "seqStart_0-input-model-BaseChatModel"
          },
          {
            "label": "Agent Memory",
            "name": "agentMemory",
            "type": "BaseCheckpointSaver",
            "description": "Save the state of the agent",
            "optional": true,
            "id": "seqStart_0-input-agentMemory-BaseCheckpointSaver"
          },
          {
            "label": "State",
            "name": "state",
            "type": "State",
            "description": "State is an object that is updated by nodes in the graph, passing from one node to another. By default, state contains \"messages\" that got updated with each message sent and received.",
            "optional": true,
            "id": "seqStart_0-input-state-State"
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "seqStart_0-input-inputModeration-Moderation"
          }
        ],
        "inputs": {
          "model": "{{groqChat_0.data.instance}}",
          "agentMemory": "",
          "state": "",
          "inputModeration": ""
        },
        "outputAnchors": [
          {
            "id": "seqStart_0-output-seqStart-Start",
            "name": "seqStart",
            "label": "Start",
            "description": "Starting point of the conversation",
            "type": "Start"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 381,
      "positionAbsolute": {
        "x": 535.1559788923448,
        "y": 183.18440211076552
      },
      "selected": false,
      "dragging": false
    },
    {
      "id": "seqEnd_0",
      "position": {
        "x": 1290.119558118808,
        "y": -313.4626022252572
      },
      "type": "customNode",
      "data": {
        "id": "seqEnd_0",
        "label": "End",
        "version": 2,
        "name": "seqEnd",
        "type": "End",
        "baseClasses": [
          "End"
        ],
        "category": "Sequential Agents",
        "description": "End conversation",
        "inputParams": [],
        "inputAnchors": [
          {
            "label": "Agent | Condition | LLM | Tool Node",
            "name": "sequentialNode",
            "type": "Agent | Condition | LLMNode | ToolNode",
            "id": "seqEnd_0-input-sequentialNode-Agent | Condition | LLMNode | ToolNode"
          }
        ],
        "inputs": {
          "sequentialNode": "{{seqConditionAgent_0.data.instance}}"
        },
        "outputAnchors": [],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 142,
      "selected": false,
      "positionAbsolute": {
        "x": 1290.119558118808,
        "y": -313.4626022252572
      },
      "dragging": false
    },
    {
      "id": "seqConditionAgent_0",
      "position": {
        "x": 1063.7462660844126,
        "y": 47.925622841110794
      },
      "type": "customNode",
      "data": {
        "id": "seqConditionAgent_0",
        "label": "Condition Agent",
        "version": 3,
        "name": "seqConditionAgent",
        "type": "ConditionAgent",
        "baseClasses": [
          "ConditionAgent"
        ],
        "category": "Sequential Agents",
        "description": "Uses an agent to determine which route to take next",
        "inputParams": [
          {
            "label": "Name",
            "name": "conditionAgentName",
            "type": "string",
            "placeholder": "Condition Agent",
            "id": "seqConditionAgent_0-input-conditionAgentName-string"
          },
          {
            "label": "System Prompt",
            "name": "systemMessagePrompt",
            "type": "string",
            "rows": 4,
            "default": "You are an expert customer support routing system.\nYour job is to detect whether a customer support representative is routing a user to the technical support team, or just responding conversationally.",
            "additionalParams": true,
            "optional": true,
            "id": "seqConditionAgent_0-input-systemMessagePrompt-string"
          },
          {
            "label": "Conversation History",
            "name": "conversationHistorySelection",
            "type": "options",
            "options": [
              {
                "label": "User Question",
                "name": "user_question",
                "description": "Use the user question from the historical conversation messages as input."
              },
              {
                "label": "Last Conversation Message",
                "name": "last_message",
                "description": "Use the last conversation message from the historical conversation messages as input."
              },
              {
                "label": "All Conversation Messages",
                "name": "all_messages",
                "description": "Use all conversation messages from the historical conversation messages as input."
              },
              {
                "label": "Empty",
                "name": "empty",
                "description": "Do not use any messages from the conversation history. Ensure to use either System Prompt, Human Prompt, or Messages History."
              }
            ],
            "default": "all_messages",
            "optional": true,
            "description": "Select which messages from the conversation history to include in the prompt. The selected messages will be inserted between the System Prompt (if defined) and Human Prompt.",
            "additionalParams": true,
            "id": "seqConditionAgent_0-input-conversationHistorySelection-options"
          },
          {
            "label": "Human Prompt",
            "name": "humanMessagePrompt",
            "type": "string",
            "description": "This prompt will be added at the end of the messages as human message",
            "rows": 4,
            "default": "The previous conversation is an interaction between a customer support representative and a user.\nExtract whether the representative is routing the user to the technical support team, or just responding conversationally.\n\nIf representative want to route the user to the technical support team, respond only with the word \"TECHNICAL\".\nOtherwise, respond only with the word \"CONVERSATION\".\n\nRemember, only respond with one of the above words.",
            "additionalParams": true,
            "optional": true,
            "id": "seqConditionAgent_0-input-humanMessagePrompt-string"
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "description": "Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "additionalParams": true,
            "id": "seqConditionAgent_0-input-promptValues-json"
          },
          {
            "label": "JSON Structured Output",
            "name": "conditionAgentStructuredOutput",
            "type": "datagrid",
            "description": "Instruct the LLM to give output in a JSON structured schema",
            "datagrid": [
              {
                "field": "key",
                "headerName": "Key",
                "editable": true
              },
              {
                "field": "type",
                "headerName": "Type",
                "type": "singleSelect",
                "valueOptions": [
                  "String",
                  "String Array",
                  "Number",
                  "Boolean",
                  "Enum"
                ],
                "editable": true
              },
              {
                "field": "enumValues",
                "headerName": "Enum Values",
                "editable": true
              },
              {
                "field": "description",
                "headerName": "Description",
                "flex": 1,
                "editable": true
              }
            ],
            "optional": true,
            "additionalParams": true,
            "id": "seqConditionAgent_0-input-conditionAgentStructuredOutput-datagrid"
          },
          {
            "label": "Condition",
            "name": "condition",
            "type": "conditionFunction",
            "tabIdentifier": "selectedConditionFunctionTab",
            "tabs": [
              {
                "label": "Condition (Table)",
                "name": "conditionUI",
                "type": "datagrid",
                "description": "If a condition is met, the node connected to the respective output will be executed",
                "optional": true,
                "datagrid": [
                  {
                    "field": "variable",
                    "headerName": "Variable",
                    "type": "freeSolo",
                    "editable": true,
                    "loadMethod": [
                      "getPreviousMessages",
                      "loadStateKeys"
                    ],
                    "valueOptions": [
                      {
                        "label": "Agent Output (string)",
                        "value": "$flow.output.content"
                      },
                      {
                        "label": "Agent's JSON Key Output (string)",
                        "value": "$flow.output.<replace-with-key>"
                      },
                      {
                        "label": "Total Messages (number)",
                        "value": "$flow.state.messages.length"
                      },
                      {
                        "label": "First Message Content (string)",
                        "value": "$flow.state.messages[0].content"
                      },
                      {
                        "label": "Last Message Content (string)",
                        "value": "$flow.state.messages[-1].content"
                      },
                      {
                        "label": "Global variable (string)",
                        "value": "$vars.<variable-name>"
                      }
                    ],
                    "flex": 0.5,
                    "minWidth": 200
                  },
                  {
                    "field": "operation",
                    "headerName": "Operation",
                    "type": "singleSelect",
                    "valueOptions": [
                      "Contains",
                      "Not Contains",
                      "Start With",
                      "End With",
                      "Is",
                      "Is Not",
                      "Is Empty",
                      "Is Not Empty",
                      "Greater Than",
                      "Less Than",
                      "Equal To",
                      "Not Equal To",
                      "Greater Than or Equal To",
                      "Less Than or Equal To"
                    ],
                    "editable": true,
                    "flex": 0.4,
                    "minWidth": 150
                  },
                  {
                    "field": "value",
                    "headerName": "Value",
                    "flex": 1,
                    "editable": true
                  },
                  {
                    "field": "output",
                    "headerName": "Output Name",
                    "editable": true,
                    "flex": 0.3,
                    "minWidth": 150
                  }
                ]
              },
              {
                "label": "Condition (Code)",
                "name": "conditionFunction",
                "type": "code",
                "description": "Function to evaluate the condition",
                "hint": {
                  "label": "How to use",
                  "value": "\n1. Must return a string value at the end of function. For example:\n    ```js\n    if (\"X\" === \"X\") {\n        return \"Agent\"; // connect to next agent node\n    } else {\n        return \"End\"; // connect to end node\n    }\n    ```\n\n2. In most cases, you would probably get the last message to do some comparison. You can get all current messages from the state: `$flow.state.messages`:\n    ```json\n    [\n        {\n            \"content\": \"Hello! How can I assist you today?\",\n            \"name\": \"\",\n            \"additional_kwargs\": {},\n            \"response_metadata\": {},\n            \"tool_calls\": [],\n            \"invalid_tool_calls\": [],\n            \"usage_metadata\": {}\n        }\n    ]\n    ```\n\n    For example, to get the last message content:\n    ```js\n    const messages = $flow.state.messages;\n    const lastMessage = messages[messages.length - 1];\n\n    // Proceed to do something with the last message content\n    ```\n\n3. If you want to use the Condition Agent's output for conditional checks, it is available as `$flow.output` with the following structure:\n\n    ```json\n    {\n        \"content\": 'Hello! How can I assist you today?',\n        \"name\": \"\",\n        \"additional_kwargs\": {},\n        \"response_metadata\": {},\n        \"tool_calls\": [],\n        \"invalid_tool_calls\": [],\n        \"usage_metadata\": {}\n    }\n    ```\n\n    For example, we can check if the agent's output contains specific keyword:\n    ```js\n    const result = $flow.output.content;\n    \n    if (result.includes(\"some-keyword\")) {\n        return \"Agent\"; // connect to next agent node\n    } else {\n        return \"End\"; // connect to end node\n    }\n    ```\n\n    If Structured Output is enabled, `$flow.output` will be in the JSON format as defined in the Structured Output configuration:\n    ```json\n    {\n        \"foo\": 'var'\n    }\n    ```\n\n4. You can get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n5. You can get custom variables: `$vars.<variable-name>`\n\n"
                },
                "hideCodeExecute": true,
                "codeExample": "const result = $flow.output.content;\n\nif (result.includes(\"some-keyword\")) {\n    return \"Agent\";\n}\n\nreturn \"End\";\n",
                "optional": true
              }
            ],
            "id": "seqConditionAgent_0-input-condition-conditionFunction"
          }
        ],
        "inputAnchors": [
          {
            "label": "Start | Agent | LLM | Tool Node",
            "name": "sequentialNode",
            "type": "Start | Agent | LLMNode | ToolNode",
            "list": true,
            "id": "seqConditionAgent_0-input-sequentialNode-Start | Agent | LLMNode | ToolNode"
          },
          {
            "label": "Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "optional": true,
            "description": "Overwrite model to be used for this agent",
            "id": "seqConditionAgent_0-input-model-BaseChatModel"
          }
        ],
        "inputs": {
          "conditionAgentName": "Router Agent",
          "sequentialNode": [
            "{{seqStart_0.data.instance}}"
          ],
          "model": "",
          "systemMessagePrompt": "Your job is to route the user to the correct team.\nFrom the user's message , try to determine if you should route the user to greeting or rag.",
          "conversationHistorySelection": "empty",
          "humanMessagePrompt": "If the user's query is related to If the user's query is related to hi,hello,hey then respond with  \"GREETING\".\n\nIf the user's query is related to Magik, User, Dashboard, Campaign,Priviledge management , Hierarchy ,Branch,Rule engine,Operators,Dimension,Segment,Cinfiguration,Profile,Action,Event ,Rule,SMS,Category,Message Template,Quarantine,Dates,Weekday,Blacklist,DND ,policy,Token,Segment,Audit details,Product catalog,Transaction,Rewards & Offers,MGM,Recommendation,Gamification,Spend&Win,Achievement,Terms &Conditions,Survey&Win,Team,Guess Game,Audience management  then respond with \"RAG\"\n\nRemember, only respond with one of the above words.",
          "promptValues": "",
          "conditionAgentStructuredOutput": "[{\"key\":\"route\",\"type\":\"Enum\",\"enumValues\":\"GREETING , RAG\",\"description\":\"the route, the user should take\",\"actions\":\"\",\"id\":0}]",
          "condition": "",
          "selectedConditionFunctionTab_seqConditionAgent_0": "conditionUI",
          "conditionUI": "[{\"variable\":\"$flow.output.route\",\"operation\":\"Is\",\"value\":\"GREETING\",\"output\":\"greeting\",\"actions\":\"\",\"id\":0},{\"variable\":\"$flow.output.route\",\"operation\":\"Is\",\"value\":\"RAG\",\"output\":\"rag\",\"actions\":\"\",\"id\":1}]"
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "options": [
              {
                "id": "seqConditionAgent_0-output-end-Condition",
                "name": "end",
                "label": "End",
                "type": "Condition",
                "isAnchor": true
              },
              {
                "id": "seqConditionAgent_0-output-greeting-Condition",
                "name": "greeting",
                "label": "greeting",
                "type": "Condition",
                "isAnchor": true
              },
              {
                "id": "seqConditionAgent_0-output-rag-Condition",
                "name": "rag",
                "label": "rag",
                "type": "Condition",
                "isAnchor": true
              }
            ]
          }
        ],
        "outputs": {
          "output": "next"
        },
        "selected": false
      },
      "width": 300,
      "height": 626,
      "selected": false,
      "positionAbsolute": {
        "x": 1063.7462660844126,
        "y": 47.925622841110794
      },
      "dragging": false
    },
    {
      "id": "seqAgent_1",
      "position": {
        "x": 1678.9042290896336,
        "y": -422.84967059313834
      },
      "type": "customNode",
      "data": {
        "id": "seqAgent_1",
        "label": "Agent",
        "version": 4,
        "name": "seqAgent",
        "type": "Agent",
        "baseClasses": [
          "Agent"
        ],
        "category": "Sequential Agents",
        "description": "Agent that can execute tools",
        "inputParams": [
          {
            "label": "Agent Name",
            "name": "agentName",
            "type": "string",
            "placeholder": "Agent",
            "id": "seqAgent_1-input-agentName-string"
          },
          {
            "label": "System Prompt",
            "name": "systemMessagePrompt",
            "type": "string",
            "rows": 4,
            "optional": true,
            "default": "You are a research assistant who can search for up-to-date info using search engine.",
            "id": "seqAgent_1-input-systemMessagePrompt-string"
          },
          {
            "label": "Prepend Messages History",
            "name": "messageHistory",
            "description": "Prepend a list of messages between System Prompt and Human Prompt. This is useful when you want to provide few shot examples",
            "type": "code",
            "hideCodeExecute": true,
            "codeExample": "const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\n\nreturn [\n    new HumanMessage(\"What is 333382 ðŸ¦œ 1932?\"),\n    new AIMessage({\n        content: \"\",\n        tool_calls: [\n        {\n            id: \"12345\",\n            name: \"calulator\",\n            args: {\n                number1: 333382,\n                number2: 1932,\n                operation: \"divide\",\n            },\n        },\n        ],\n    }),\n    new ToolMessage({\n        tool_call_id: \"12345\",\n        content: \"The answer is 172.558.\",\n    }),\n    new AIMessage(\"The answer is 172.558.\"),\n]",
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_1-input-messageHistory-code"
          },
          {
            "label": "Conversation History",
            "name": "conversationHistorySelection",
            "type": "options",
            "options": [
              {
                "label": "User Question",
                "name": "user_question",
                "description": "Use the user question from the historical conversation messages as input."
              },
              {
                "label": "Last Conversation Message",
                "name": "last_message",
                "description": "Use the last conversation message from the historical conversation messages as input."
              },
              {
                "label": "All Conversation Messages",
                "name": "all_messages",
                "description": "Use all conversation messages from the historical conversation messages as input."
              },
              {
                "label": "Empty",
                "name": "empty",
                "description": "Do not use any messages from the conversation history. Ensure to use either System Prompt, Human Prompt, or Messages History."
              }
            ],
            "default": "all_messages",
            "optional": true,
            "description": "Select which messages from the conversation history to include in the prompt. The selected messages will be inserted between the System Prompt (if defined) and [Messages History, Human Prompt].",
            "additionalParams": true,
            "id": "seqAgent_1-input-conversationHistorySelection-options"
          },
          {
            "label": "Human Prompt",
            "name": "humanMessagePrompt",
            "type": "string",
            "description": "This prompt will be added at the end of the messages as human message",
            "rows": 4,
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_1-input-humanMessagePrompt-string"
          },
          {
            "label": "Require Approval",
            "name": "interrupt",
            "description": "Pause execution and request user approval before running tools.\nIf enabled, the agent will prompt the user with customizable approve/reject options\nand will proceed only after approval. This requires a configured agent memory to manage\nthe state and handle approval requests.\nIf no tools are invoked, the agent proceeds without interruption.",
            "type": "boolean",
            "optional": true,
            "id": "seqAgent_1-input-interrupt-boolean"
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "description": "Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "seqAgent_1-input-promptValues-json"
          },
          {
            "label": "Approval Prompt",
            "name": "approvalPrompt",
            "description": "Prompt for approval. Only applicable if \"Require Approval\" is enabled",
            "type": "string",
            "default": "You are about to execute tool: {tools}. Ask if user want to proceed",
            "rows": 4,
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_1-input-approvalPrompt-string"
          },
          {
            "label": "Approve Button Text",
            "name": "approveButtonText",
            "description": "Text for approve button. Only applicable if \"Require Approval\" is enabled",
            "type": "string",
            "default": "Yes",
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_1-input-approveButtonText-string"
          },
          {
            "label": "Reject Button Text",
            "name": "rejectButtonText",
            "description": "Text for reject button. Only applicable if \"Require Approval\" is enabled",
            "type": "string",
            "default": "No",
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_1-input-rejectButtonText-string"
          },
          {
            "label": "Update State",
            "name": "updateStateMemory",
            "type": "tabs",
            "tabIdentifier": "selectedUpdateStateMemoryTab",
            "additionalParams": true,
            "default": "updateStateMemoryUI",
            "tabs": [
              {
                "label": "Update State (Table)",
                "name": "updateStateMemoryUI",
                "type": "datagrid",
                "hint": {
                  "label": "How to use",
                  "value": "\n1. Key and value pair to be updated. For example: if you have the following State:\n    | Key       | Operation     | Default Value     |\n    |-----------|---------------|-------------------|\n    | user      | Replace       |                   |\n\n    You can update the \"user\" value with the following:\n    | Key       | Value     |\n    |-----------|-----------|\n    | user      | john doe  |\n\n2. If you want to use the Agent's output as the value to update state, it is available as available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": \"Hello! How can I assist you today?\",\n        \"usedTools\": [\n            {\n                \"tool\": \"tool-name\",\n                \"toolInput\": \"{foo: var}\",\n                \"toolOutput\": \"This is the tool's output\"\n            }\n        ],\n        \"sourceDocuments\": [\n            {\n                \"pageContent\": \"This is the page content\",\n                \"metadata\": \"{foo: var}\"\n            }\n        ]\n    }\n    ```\n\n    For example, if the `toolOutput` is the value you want to update the state with, you can do the following:\n    | Key       | Value                                     |\n    |-----------|-------------------------------------------|\n    | user      | `$flow.output.usedTools[0].toolOutput`  |\n\n3. You can get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                },
                "description": "This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values",
                "datagrid": [
                  {
                    "field": "key",
                    "headerName": "Key",
                    "type": "asyncSingleSelect",
                    "loadMethod": "loadStateKeys",
                    "flex": 0.5,
                    "editable": true
                  },
                  {
                    "field": "value",
                    "headerName": "Value",
                    "type": "freeSolo",
                    "valueOptions": [
                      {
                        "label": "Agent Output (string)",
                        "value": "$flow.output.content"
                      },
                      {
                        "label": "Used Tools (array)",
                        "value": "$flow.output.usedTools"
                      },
                      {
                        "label": "First Tool Output (string)",
                        "value": "$flow.output.usedTools[0].toolOutput"
                      },
                      {
                        "label": "Source Documents (array)",
                        "value": "$flow.output.sourceDocuments"
                      },
                      {
                        "label": "Global variable (string)",
                        "value": "$vars.<variable-name>"
                      },
                      {
                        "label": "Input Question (string)",
                        "value": "$flow.input"
                      },
                      {
                        "label": "Session Id (string)",
                        "value": "$flow.sessionId"
                      },
                      {
                        "label": "Chat Id (string)",
                        "value": "$flow.chatId"
                      },
                      {
                        "label": "Chatflow Id (string)",
                        "value": "$flow.chatflowId"
                      }
                    ],
                    "editable": true,
                    "flex": 1
                  }
                ],
                "optional": true,
                "additionalParams": true
              },
              {
                "label": "Update State (Code)",
                "name": "updateStateMemoryCode",
                "type": "code",
                "hint": {
                  "label": "How to use",
                  "value": "\n1. Return the key value JSON object. For example: if you have the following State:\n    ```json\n    {\n        \"user\": null\n    }\n    ```\n\n    You can update the \"user\" value by returning the following:\n    ```js\n    return {\n        \"user\": \"john doe\"\n    }\n    ```\n\n2. If you want to use the agent's output as the value to update state, it is available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": \"Hello! How can I assist you today?\",\n        \"usedTools\": [\n            {\n                \"tool\": \"tool-name\",\n                \"toolInput\": \"{foo: var}\",\n                \"toolOutput\": \"This is the tool's output\"\n            }\n        ],\n        \"sourceDocuments\": [\n            {\n                \"pageContent\": \"This is the page content\",\n                \"metadata\": \"{foo: var}\"\n            }\n        ]\n    }\n    ```\n\n    For example, if the `toolOutput` is the value you want to update the state with, you can return the following:\n    ```js\n    return {\n        \"user\": $flow.output.usedTools[0].toolOutput\n    }\n    ```\n\n3. You can also get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                },
                "description": "This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values. Must return an object representing the state",
                "hideCodeExecute": true,
                "codeExample": "const result = $flow.output;\n\n/* Suppose we have a custom State schema like this:\n* {\n    aggregate: {\n        value: (x, y) => x.concat(y),\n        default: () => []\n    }\n  }\n*/\n\nreturn {\n  aggregate: [result.content]\n};",
                "optional": true,
                "additionalParams": true
              }
            ],
            "id": "seqAgent_1-input-updateStateMemory-tabs"
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_1-input-maxIterations-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "optional": true,
            "id": "seqAgent_1-input-tools-Tool"
          },
          {
            "label": "Start | Agent | Condition | LLM | Tool Node",
            "name": "sequentialNode",
            "type": "Start | Agent | Condition | LLMNode | ToolNode",
            "list": true,
            "id": "seqAgent_1-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode"
          },
          {
            "label": "Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "optional": true,
            "description": "Overwrite model to be used for this agent",
            "id": "seqAgent_1-input-model-BaseChatModel"
          }
        ],
        "inputs": {
          "agentName": "Greeting Team",
          "systemMessagePrompt": "You are a Greeting Assistant, as a Greeting Assistant, your primary role is to warmly welcome users and offer assistance based on their initial interactions. \n\nResponse Guidelines:\nBasic Greetings:\nIf a user greets you with \"Hello,\" \"Hi,\" or \"Hey,\" respond with:\n\"Hello! How may I assist you today?\"",
          "messageHistory": "",
          "conversationHistorySelection": "all_messages",
          "humanMessagePrompt": "",
          "tools": [],
          "sequentialNode": [
            "{{seqConditionAgent_0.data.instance}}"
          ],
          "model": "",
          "interrupt": false,
          "promptValues": "",
          "approvalPrompt": "You are about to execute tool: {tools}. Ask if user want to proceed",
          "approveButtonText": "Yes",
          "rejectButtonText": "No",
          "updateStateMemory": "updateStateMemoryUI",
          "maxIterations": "",
          "selectedUpdateStateMemoryTab_seqAgent_1": "updateStateMemoryUI"
        },
        "outputAnchors": [
          {
            "id": "seqAgent_1-output-seqAgent-Agent",
            "name": "seqAgent",
            "label": "Agent",
            "description": "Agent that can execute tools",
            "type": "Agent"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 876,
      "selected": false,
      "positionAbsolute": {
        "x": 1678.9042290896336,
        "y": -422.84967059313834
      },
      "dragging": false
    },
    {
      "id": "seqAgent_2",
      "position": {
        "x": 1685.181693772893,
        "y": 592.3368665470862
      },
      "type": "customNode",
      "data": {
        "id": "seqAgent_2",
        "label": "Agent",
        "version": 4,
        "name": "seqAgent",
        "type": "Agent",
        "baseClasses": [
          "Agent"
        ],
        "category": "Sequential Agents",
        "description": "Agent that can execute tools",
        "inputParams": [
          {
            "label": "Agent Name",
            "name": "agentName",
            "type": "string",
            "placeholder": "Agent",
            "id": "seqAgent_2-input-agentName-string"
          },
          {
            "label": "System Prompt",
            "name": "systemMessagePrompt",
            "type": "string",
            "rows": 4,
            "optional": true,
            "default": "You are a research assistant who can search for up-to-date info using search engine.",
            "id": "seqAgent_2-input-systemMessagePrompt-string"
          },
          {
            "label": "Prepend Messages History",
            "name": "messageHistory",
            "description": "Prepend a list of messages between System Prompt and Human Prompt. This is useful when you want to provide few shot examples",
            "type": "code",
            "hideCodeExecute": true,
            "codeExample": "const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\n\nreturn [\n    new HumanMessage(\"What is 333382 ðŸ¦œ 1932?\"),\n    new AIMessage({\n        content: \"\",\n        tool_calls: [\n        {\n            id: \"12345\",\n            name: \"calulator\",\n            args: {\n                number1: 333382,\n                number2: 1932,\n                operation: \"divide\",\n            },\n        },\n        ],\n    }),\n    new ToolMessage({\n        tool_call_id: \"12345\",\n        content: \"The answer is 172.558.\",\n    }),\n    new AIMessage(\"The answer is 172.558.\"),\n]",
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_2-input-messageHistory-code"
          },
          {
            "label": "Conversation History",
            "name": "conversationHistorySelection",
            "type": "options",
            "options": [
              {
                "label": "User Question",
                "name": "user_question",
                "description": "Use the user question from the historical conversation messages as input."
              },
              {
                "label": "Last Conversation Message",
                "name": "last_message",
                "description": "Use the last conversation message from the historical conversation messages as input."
              },
              {
                "label": "All Conversation Messages",
                "name": "all_messages",
                "description": "Use all conversation messages from the historical conversation messages as input."
              },
              {
                "label": "Empty",
                "name": "empty",
                "description": "Do not use any messages from the conversation history. Ensure to use either System Prompt, Human Prompt, or Messages History."
              }
            ],
            "default": "all_messages",
            "optional": true,
            "description": "Select which messages from the conversation history to include in the prompt. The selected messages will be inserted between the System Prompt (if defined) and [Messages History, Human Prompt].",
            "additionalParams": true,
            "id": "seqAgent_2-input-conversationHistorySelection-options"
          },
          {
            "label": "Human Prompt",
            "name": "humanMessagePrompt",
            "type": "string",
            "description": "This prompt will be added at the end of the messages as human message",
            "rows": 4,
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_2-input-humanMessagePrompt-string"
          },
          {
            "label": "Require Approval",
            "name": "interrupt",
            "description": "Pause execution and request user approval before running tools.\nIf enabled, the agent will prompt the user with customizable approve/reject options\nand will proceed only after approval. This requires a configured agent memory to manage\nthe state and handle approval requests.\nIf no tools are invoked, the agent proceeds without interruption.",
            "type": "boolean",
            "optional": true,
            "id": "seqAgent_2-input-interrupt-boolean"
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "description": "Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "seqAgent_2-input-promptValues-json"
          },
          {
            "label": "Approval Prompt",
            "name": "approvalPrompt",
            "description": "Prompt for approval. Only applicable if \"Require Approval\" is enabled",
            "type": "string",
            "default": "You are about to execute tool: {tools}. Ask if user want to proceed",
            "rows": 4,
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_2-input-approvalPrompt-string"
          },
          {
            "label": "Approve Button Text",
            "name": "approveButtonText",
            "description": "Text for approve button. Only applicable if \"Require Approval\" is enabled",
            "type": "string",
            "default": "Yes",
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_2-input-approveButtonText-string"
          },
          {
            "label": "Reject Button Text",
            "name": "rejectButtonText",
            "description": "Text for reject button. Only applicable if \"Require Approval\" is enabled",
            "type": "string",
            "default": "No",
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_2-input-rejectButtonText-string"
          },
          {
            "label": "Update State",
            "name": "updateStateMemory",
            "type": "tabs",
            "tabIdentifier": "selectedUpdateStateMemoryTab",
            "additionalParams": true,
            "default": "updateStateMemoryUI",
            "tabs": [
              {
                "label": "Update State (Table)",
                "name": "updateStateMemoryUI",
                "type": "datagrid",
                "hint": {
                  "label": "How to use",
                  "value": "\n1. Key and value pair to be updated. For example: if you have the following State:\n    | Key       | Operation     | Default Value     |\n    |-----------|---------------|-------------------|\n    | user      | Replace       |                   |\n\n    You can update the \"user\" value with the following:\n    | Key       | Value     |\n    |-----------|-----------|\n    | user      | john doe  |\n\n2. If you want to use the Agent's output as the value to update state, it is available as available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": \"Hello! How can I assist you today?\",\n        \"usedTools\": [\n            {\n                \"tool\": \"tool-name\",\n                \"toolInput\": \"{foo: var}\",\n                \"toolOutput\": \"This is the tool's output\"\n            }\n        ],\n        \"sourceDocuments\": [\n            {\n                \"pageContent\": \"This is the page content\",\n                \"metadata\": \"{foo: var}\"\n            }\n        ]\n    }\n    ```\n\n    For example, if the `toolOutput` is the value you want to update the state with, you can do the following:\n    | Key       | Value                                     |\n    |-----------|-------------------------------------------|\n    | user      | `$flow.output.usedTools[0].toolOutput`  |\n\n3. You can get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                },
                "description": "This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values",
                "datagrid": [
                  {
                    "field": "key",
                    "headerName": "Key",
                    "type": "asyncSingleSelect",
                    "loadMethod": "loadStateKeys",
                    "flex": 0.5,
                    "editable": true
                  },
                  {
                    "field": "value",
                    "headerName": "Value",
                    "type": "freeSolo",
                    "valueOptions": [
                      {
                        "label": "Agent Output (string)",
                        "value": "$flow.output.content"
                      },
                      {
                        "label": "Used Tools (array)",
                        "value": "$flow.output.usedTools"
                      },
                      {
                        "label": "First Tool Output (string)",
                        "value": "$flow.output.usedTools[0].toolOutput"
                      },
                      {
                        "label": "Source Documents (array)",
                        "value": "$flow.output.sourceDocuments"
                      },
                      {
                        "label": "Global variable (string)",
                        "value": "$vars.<variable-name>"
                      },
                      {
                        "label": "Input Question (string)",
                        "value": "$flow.input"
                      },
                      {
                        "label": "Session Id (string)",
                        "value": "$flow.sessionId"
                      },
                      {
                        "label": "Chat Id (string)",
                        "value": "$flow.chatId"
                      },
                      {
                        "label": "Chatflow Id (string)",
                        "value": "$flow.chatflowId"
                      }
                    ],
                    "editable": true,
                    "flex": 1
                  }
                ],
                "optional": true,
                "additionalParams": true
              },
              {
                "label": "Update State (Code)",
                "name": "updateStateMemoryCode",
                "type": "code",
                "hint": {
                  "label": "How to use",
                  "value": "\n1. Return the key value JSON object. For example: if you have the following State:\n    ```json\n    {\n        \"user\": null\n    }\n    ```\n\n    You can update the \"user\" value by returning the following:\n    ```js\n    return {\n        \"user\": \"john doe\"\n    }\n    ```\n\n2. If you want to use the agent's output as the value to update state, it is available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": \"Hello! How can I assist you today?\",\n        \"usedTools\": [\n            {\n                \"tool\": \"tool-name\",\n                \"toolInput\": \"{foo: var}\",\n                \"toolOutput\": \"This is the tool's output\"\n            }\n        ],\n        \"sourceDocuments\": [\n            {\n                \"pageContent\": \"This is the page content\",\n                \"metadata\": \"{foo: var}\"\n            }\n        ]\n    }\n    ```\n\n    For example, if the `toolOutput` is the value you want to update the state with, you can return the following:\n    ```js\n    return {\n        \"user\": $flow.output.usedTools[0].toolOutput\n    }\n    ```\n\n3. You can also get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                },
                "description": "This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values. Must return an object representing the state",
                "hideCodeExecute": true,
                "codeExample": "const result = $flow.output;\n\n/* Suppose we have a custom State schema like this:\n* {\n    aggregate: {\n        value: (x, y) => x.concat(y),\n        default: () => []\n    }\n  }\n*/\n\nreturn {\n  aggregate: [result.content]\n};",
                "optional": true,
                "additionalParams": true
              }
            ],
            "id": "seqAgent_2-input-updateStateMemory-tabs"
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "seqAgent_2-input-maxIterations-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "optional": true,
            "id": "seqAgent_2-input-tools-Tool"
          },
          {
            "label": "Start | Agent | Condition | LLM | Tool Node",
            "name": "sequentialNode",
            "type": "Start | Agent | Condition | LLMNode | ToolNode",
            "list": true,
            "id": "seqAgent_2-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode"
          },
          {
            "label": "Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "optional": true,
            "description": "Overwrite model to be used for this agent",
            "id": "seqAgent_2-input-model-BaseChatModel"
          }
        ],
        "inputs": {
          "agentName": "RAG Team",
          "systemMessagePrompt": "You are the RAG Assistant. Your primary task is to efficiently retrieve and provide accurate information using the \"user_info\" retriever tool. If no information is available , respond with \"I don't know.\"\n\nResponse Guidelines:\n- Direct and Concise Responses: Provide straightforward answers without unnecessary details or elaboration.\n- No Fabrication: Do not guess or create information. Only respond based on data retrieved from the \"user_info\" tool.\n- Avoid Specific Phrases: Refrain from using phrases such as \"Note\" or any similar expressions.\n-Stay On Topic: Respond strictly to the user's query without offering additional or unrelated information.\n-Clarity: Ensure your responses are easy to understand and address the user's question directly.",
          "messageHistory": "",
          "conversationHistorySelection": "all_messages",
          "humanMessagePrompt": "",
          "tools": [
            "{{retrieverTool_0.data.instance}}"
          ],
          "sequentialNode": [
            "{{seqConditionAgent_0.data.instance}}"
          ],
          "model": "",
          "interrupt": "",
          "promptValues": "",
          "approvalPrompt": "You are about to execute tool: {tools}. Ask if user want to proceed",
          "approveButtonText": "Yes",
          "rejectButtonText": "No",
          "updateStateMemory": "updateStateMemoryUI",
          "maxIterations": "",
          "selectedUpdateStateMemoryTab_seqAgent_2": "updateStateMemoryUI"
        },
        "outputAnchors": [
          {
            "id": "seqAgent_2-output-seqAgent-Agent",
            "name": "seqAgent",
            "label": "Agent",
            "description": "Agent that can execute tools",
            "type": "Agent"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 876,
      "selected": false,
      "positionAbsolute": {
        "x": 1685.181693772893,
        "y": 592.3368665470862
      },
      "dragging": false
    },
    {
      "id": "seqEnd_1",
      "position": {
        "x": 2033.8010583669247,
        "y": 197.0727109141685
      },
      "type": "customNode",
      "data": {
        "id": "seqEnd_1",
        "label": "End",
        "version": 2,
        "name": "seqEnd",
        "type": "End",
        "baseClasses": [
          "End"
        ],
        "category": "Sequential Agents",
        "description": "End conversation",
        "inputParams": [],
        "inputAnchors": [
          {
            "label": "Agent | Condition | LLM | Tool Node",
            "name": "sequentialNode",
            "type": "Agent | Condition | LLMNode | ToolNode",
            "id": "seqEnd_1-input-sequentialNode-Agent | Condition | LLMNode | ToolNode"
          }
        ],
        "inputs": {
          "sequentialNode": "{{seqAgent_1.data.instance}}"
        },
        "outputAnchors": [],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 142,
      "selected": false,
      "positionAbsolute": {
        "x": 2033.8010583669247,
        "y": 197.0727109141685
      },
      "dragging": false
    },
    {
      "id": "seqEnd_2",
      "position": {
        "x": 2035.3565415977605,
        "y": 1212.0781087778435
      },
      "type": "customNode",
      "data": {
        "id": "seqEnd_2",
        "label": "End",
        "version": 2,
        "name": "seqEnd",
        "type": "End",
        "baseClasses": [
          "End"
        ],
        "category": "Sequential Agents",
        "description": "End conversation",
        "inputParams": [],
        "inputAnchors": [
          {
            "label": "Agent | Condition | LLM | Tool Node",
            "name": "sequentialNode",
            "type": "Agent | Condition | LLMNode | ToolNode",
            "id": "seqEnd_2-input-sequentialNode-Agent | Condition | LLMNode | ToolNode"
          }
        ],
        "inputs": {
          "sequentialNode": "{{seqAgent_2.data.instance}}"
        },
        "outputAnchors": [],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 142,
      "selected": false,
      "positionAbsolute": {
        "x": 2035.3565415977605,
        "y": 1212.0781087778435
      },
      "dragging": false
    },
    {
      "id": "retrieverTool_0",
      "position": {
        "x": 1281.4243491233265,
        "y": 769.9943552071177
      },
      "type": "customNode",
      "data": {
        "id": "retrieverTool_0",
        "label": "Retriever Tool",
        "version": 3,
        "name": "retrieverTool",
        "type": "RetrieverTool",
        "baseClasses": [
          "RetrieverTool",
          "DynamicTool",
          "Tool",
          "StructuredTool",
          "Runnable"
        ],
        "category": "Tools",
        "description": "Use a retriever as allowed tool for agent",
        "inputParams": [
          {
            "label": "Retriever Name",
            "name": "name",
            "type": "string",
            "placeholder": "search_state_of_union",
            "id": "retrieverTool_0-input-name-string"
          },
          {
            "label": "Retriever Description",
            "name": "description",
            "type": "string",
            "description": "When should agent uses to retrieve documents",
            "rows": 3,
            "placeholder": "Searches and returns documents regarding the state-of-the-union.",
            "id": "retrieverTool_0-input-description-string"
          },
          {
            "label": "Return Source Documents",
            "name": "returnSourceDocuments",
            "type": "boolean",
            "optional": true,
            "id": "retrieverTool_0-input-returnSourceDocuments-boolean"
          },
          {
            "label": "Additional Metadata Filter",
            "name": "retrieverToolMetadataFilter",
            "type": "json",
            "description": "Add additional metadata filter on top of the existing filter from vector store",
            "optional": true,
            "additionalParams": true,
            "hint": {
              "label": "What can you filter?",
              "value": "Add additional filters to vector store. You can also filter with flow config, including the current \"state\":\n- `$flow.sessionId`\n- `$flow.chatId`\n- `$flow.chatflowId`\n- `$flow.input`\n- `$flow.state`\n"
            },
            "id": "retrieverTool_0-input-retrieverToolMetadataFilter-json"
          }
        ],
        "inputAnchors": [
          {
            "label": "Retriever",
            "name": "retriever",
            "type": "BaseRetriever",
            "id": "retrieverTool_0-input-retriever-BaseRetriever"
          }
        ],
        "inputs": {
          "name": "user_info",
          "description": "Searches and return dcouments regarding Magik, User, Dashboard, Campaign,Priviledge management , Hierarchy ,Branch,Rule engine,Operators,Dimension,Segment,Cinfiguration,Profile,Action,Event ,Rule,SMS,Category,Message Template,Quarantine,Dates,Weekday,Blacklist,DND ,policy,Token,Segment,Audit details,Product catalog,Transaction,Rewards & Offers,MGM,Recommendation,Gamification,Spend&Win,Achievement,Terms &Conditions,Survey&Win,Team,Guess Game,Audience management .",
          "retriever": "{{memoryVectorStore_0.data.instance}}",
          "returnSourceDocuments": true,
          "retrieverToolMetadataFilter": ""
        },
        "outputAnchors": [
          {
            "id": "retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable",
            "name": "retrieverTool",
            "label": "RetrieverTool",
            "description": "Use a retriever as allowed tool for agent",
            "type": "RetrieverTool | DynamicTool | Tool | StructuredTool | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 653,
      "selected": false,
      "positionAbsolute": {
        "x": 1281.4243491233265,
        "y": 769.9943552071177
      },
      "dragging": false
    },
    {
      "id": "groqChat_0",
      "position": {
        "x": 96.66353514354856,
        "y": 56.87033475491819
      },
      "type": "customNode",
      "data": {
        "id": "groqChat_0",
        "label": "GroqChat",
        "version": 4,
        "name": "groqChat",
        "type": "GroqChat",
        "baseClasses": [
          "GroqChat",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around Groq API with LPU Inference Engine",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "groqApi"
            ],
            "optional": true,
            "id": "groqChat_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "placeholder": "llama3-70b-8192",
            "id": "groqChat_0-input-modelName-asyncOptions"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "groqChat_0-input-temperature-number"
          },
          {
            "label": "Streaming",
            "name": "streaming",
            "type": "boolean",
            "default": true,
            "optional": true,
            "id": "groqChat_0-input-streaming-boolean"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "groqChat_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "llama3-70b-8192",
          "temperature": "1.9",
          "streaming": true
        },
        "outputAnchors": [
          {
            "id": "groqChat_0-output-groqChat-GroqChat|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "groqChat",
            "label": "GroqChat",
            "description": "Wrapper around Groq API with LPU Inference Engine",
            "type": "GroqChat | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 616,
      "positionAbsolute": {
        "x": 96.66353514354856,
        "y": 56.87033475491819
      },
      "selected": false,
      "dragging": false
    },
    {
      "id": "huggingFaceInferenceEmbeddings_0",
      "position": {
        "x": 497.52526489064815,
        "y": 827.0051386469822
      },
      "type": "customNode",
      "data": {
        "id": "huggingFaceInferenceEmbeddings_0",
        "label": "HuggingFace Inference Embeddings",
        "version": 1,
        "name": "huggingFaceInferenceEmbeddings",
        "type": "HuggingFaceInferenceEmbeddings",
        "baseClasses": [
          "HuggingFaceInferenceEmbeddings",
          "Embeddings"
        ],
        "category": "Embeddings",
        "description": "HuggingFace Inference API to generate embeddings for a given text",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "huggingFaceApi"
            ],
            "id": "huggingFaceInferenceEmbeddings_0-input-credential-credential"
          },
          {
            "label": "Model",
            "name": "modelName",
            "type": "string",
            "description": "If using own inference endpoint, leave this blank",
            "placeholder": "sentence-transformers/distilbert-base-nli-mean-tokens",
            "optional": true,
            "id": "huggingFaceInferenceEmbeddings_0-input-modelName-string"
          },
          {
            "label": "Endpoint",
            "name": "endpoint",
            "type": "string",
            "placeholder": "https://xyz.eu-west-1.aws.endpoints.huggingface.cloud/sentence-transformers/all-MiniLM-L6-v2",
            "description": "Using your own inference endpoint",
            "optional": true,
            "id": "huggingFaceInferenceEmbeddings_0-input-endpoint-string"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "modelName": "sentence-transformers/distiluse-base-multilingual-cased-v1",
          "endpoint": ""
        },
        "outputAnchors": [
          {
            "id": "huggingFaceInferenceEmbeddings_0-output-huggingFaceInferenceEmbeddings-HuggingFaceInferenceEmbeddings|Embeddings",
            "name": "huggingFaceInferenceEmbeddings",
            "label": "HuggingFaceInferenceEmbeddings",
            "description": "HuggingFace Inference API to generate embeddings for a given text",
            "type": "HuggingFaceInferenceEmbeddings | Embeddings"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 471,
      "selected": false,
      "positionAbsolute": {
        "x": 497.52526489064815,
        "y": 827.0051386469822
      },
      "dragging": false
    },
    {
      "id": "memoryVectorStore_0",
      "position": {
        "x": 877.1897158680322,
        "y": 887.4063013024752
      },
      "type": "customNode",
      "data": {
        "id": "memoryVectorStore_0",
        "label": "In-Memory Vector Store",
        "version": 1,
        "name": "memoryVectorStore",
        "type": "Memory",
        "baseClasses": [
          "Memory",
          "VectorStoreRetriever",
          "BaseRetriever"
        ],
        "category": "Vector Stores",
        "description": "In-memory vectorstore that stores embeddings and does an exact, linear search for the most similar embeddings.",
        "inputParams": [
          {
            "label": "Top K",
            "name": "topK",
            "description": "Number of top results to fetch. Default to 4",
            "placeholder": "4",
            "type": "number",
            "optional": true,
            "id": "memoryVectorStore_0-input-topK-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Document",
            "name": "document",
            "type": "Document",
            "list": true,
            "optional": true,
            "id": "memoryVectorStore_0-input-document-Document"
          },
          {
            "label": "Embeddings",
            "name": "embeddings",
            "type": "Embeddings",
            "id": "memoryVectorStore_0-input-embeddings-Embeddings"
          }
        ],
        "inputs": {
          "document": [
            "{{documentStore_0.data.instance}}"
          ],
          "embeddings": "{{huggingFaceInferenceEmbeddings_0.data.instance}}",
          "topK": ""
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "memoryVectorStore_0-output-retriever-Memory|VectorStoreRetriever|BaseRetriever",
                "name": "retriever",
                "label": "Memory Retriever",
                "description": "",
                "type": "Memory | VectorStoreRetriever | BaseRetriever"
              },
              {
                "id": "memoryVectorStore_0-output-vectorStore-Memory|VectorStore",
                "name": "vectorStore",
                "label": "Memory Vector Store",
                "description": "",
                "type": "Memory | VectorStore"
              }
            ],
            "default": "retriever"
          }
        ],
        "outputs": {
          "output": "retriever"
        },
        "selected": false
      },
      "width": 300,
      "height": 405,
      "selected": false,
      "positionAbsolute": {
        "x": 877.1897158680322,
        "y": 887.4063013024752
      },
      "dragging": false
    },
    {
      "id": "documentStore_0",
      "position": {
        "x": 85.5030482049637,
        "y": 786.0186354164691
      },
      "type": "customNode",
      "data": {
        "id": "documentStore_0",
        "label": "Document Store",
        "version": 1,
        "name": "documentStore",
        "type": "Document",
        "baseClasses": [
          "Document"
        ],
        "category": "Document Loaders",
        "description": "Load data from pre-configured document stores",
        "inputParams": [
          {
            "label": "Select Store",
            "name": "selectedStore",
            "type": "asyncOptions",
            "loadMethod": "listStores",
            "id": "documentStore_0-input-selectedStore-asyncOptions"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "selectedStore": "e83d4734-4a37-49f9-8427-c68dbec8891e"
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "Array of document objects containing metadata and pageContent",
            "options": [
              {
                "id": "documentStore_0-output-document-Document|json",
                "name": "document",
                "label": "Document",
                "description": "Array of document objects containing metadata and pageContent",
                "type": "Document | json"
              },
              {
                "id": "documentStore_0-output-text-string|json",
                "name": "text",
                "label": "Text",
                "description": "Concatenated string from pageContent of documents",
                "type": "string | json"
              }
            ],
            "default": "document"
          }
        ],
        "outputs": {
          "output": "document"
        },
        "selected": false
      },
      "width": 300,
      "height": 310,
      "selected": false,
      "positionAbsolute": {
        "x": 85.5030482049637,
        "y": 786.0186354164691
      },
      "dragging": false
    }
  ],
  "edges": [
    {
      "source": "retrieverTool_0",
      "sourceHandle": "retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable",
      "target": "seqAgent_2",
      "targetHandle": "seqAgent_2-input-tools-Tool",
      "type": "buttonedge",
      "id": "retrieverTool_0-retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable-seqAgent_2-seqAgent_2-input-tools-Tool"
    },
    {
      "source": "seqAgent_2",
      "sourceHandle": "seqAgent_2-output-seqAgent-Agent",
      "target": "seqEnd_2",
      "targetHandle": "seqEnd_2-input-sequentialNode-Agent | Condition | LLMNode | ToolNode",
      "type": "buttonedge",
      "id": "seqAgent_2-seqAgent_2-output-seqAgent-Agent-seqEnd_2-seqEnd_2-input-sequentialNode-Agent | Condition | LLMNode | ToolNode"
    },
    {
      "source": "seqAgent_1",
      "sourceHandle": "seqAgent_1-output-seqAgent-Agent",
      "target": "seqEnd_1",
      "targetHandle": "seqEnd_1-input-sequentialNode-Agent | Condition | LLMNode | ToolNode",
      "type": "buttonedge",
      "id": "seqAgent_1-seqAgent_1-output-seqAgent-Agent-seqEnd_1-seqEnd_1-input-sequentialNode-Agent | Condition | LLMNode | ToolNode"
    },
    {
      "source": "groqChat_0",
      "sourceHandle": "groqChat_0-output-groqChat-GroqChat|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "seqStart_0",
      "targetHandle": "seqStart_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "groqChat_0-groqChat_0-output-groqChat-GroqChat|BaseChatModel|BaseLanguageModel|Runnable-seqStart_0-seqStart_0-input-model-BaseChatModel"
    },
    {
      "source": "seqStart_0",
      "sourceHandle": "seqStart_0-output-seqStart-Start",
      "target": "seqConditionAgent_0",
      "targetHandle": "seqConditionAgent_0-input-sequentialNode-Start | Agent | LLMNode | ToolNode",
      "type": "buttonedge",
      "id": "seqStart_0-seqStart_0-output-seqStart-Start-seqConditionAgent_0-seqConditionAgent_0-input-sequentialNode-Start | Agent | LLMNode | ToolNode"
    },
    {
      "source": "huggingFaceInferenceEmbeddings_0",
      "sourceHandle": "huggingFaceInferenceEmbeddings_0-output-huggingFaceInferenceEmbeddings-HuggingFaceInferenceEmbeddings|Embeddings",
      "target": "memoryVectorStore_0",
      "targetHandle": "memoryVectorStore_0-input-embeddings-Embeddings",
      "type": "buttonedge",
      "id": "huggingFaceInferenceEmbeddings_0-huggingFaceInferenceEmbeddings_0-output-huggingFaceInferenceEmbeddings-HuggingFaceInferenceEmbeddings|Embeddings-memoryVectorStore_0-memoryVectorStore_0-input-embeddings-Embeddings"
    },
    {
      "source": "memoryVectorStore_0",
      "sourceHandle": "memoryVectorStore_0-output-retriever-Memory|VectorStoreRetriever|BaseRetriever",
      "target": "retrieverTool_0",
      "targetHandle": "retrieverTool_0-input-retriever-BaseRetriever",
      "type": "buttonedge",
      "id": "memoryVectorStore_0-memoryVectorStore_0-output-retriever-Memory|VectorStoreRetriever|BaseRetriever-retrieverTool_0-retrieverTool_0-input-retriever-BaseRetriever"
    },
    {
      "source": "documentStore_0",
      "sourceHandle": "documentStore_0-output-document-Document|json",
      "target": "memoryVectorStore_0",
      "targetHandle": "memoryVectorStore_0-input-document-Document",
      "type": "buttonedge",
      "id": "documentStore_0-documentStore_0-output-document-Document|json-memoryVectorStore_0-memoryVectorStore_0-input-document-Document"
    },
    {
      "source": "seqConditionAgent_0",
      "sourceHandle": "seqConditionAgent_0-output-end-Condition",
      "target": "seqEnd_0",
      "targetHandle": "seqEnd_0-input-sequentialNode-Agent | Condition | LLMNode | ToolNode",
      "type": "buttonedge",
      "id": "seqConditionAgent_0-seqConditionAgent_0-output-end-Condition-seqEnd_0-seqEnd_0-input-sequentialNode-Agent | Condition | LLMNode | ToolNode"
    },
    {
      "source": "seqConditionAgent_0",
      "sourceHandle": "seqConditionAgent_0-output-greeting-Condition",
      "target": "seqAgent_1",
      "targetHandle": "seqAgent_1-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode",
      "type": "buttonedge",
      "id": "seqConditionAgent_0-seqConditionAgent_0-output-greeting-Condition-seqAgent_1-seqAgent_1-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode"
    },
    {
      "source": "seqConditionAgent_0",
      "sourceHandle": "seqConditionAgent_0-output-rag-Condition",
      "target": "seqAgent_2",
      "targetHandle": "seqAgent_2-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode",
      "type": "buttonedge",
      "id": "seqConditionAgent_0-seqConditionAgent_0-output-rag-Condition-seqAgent_2-seqAgent_2-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode"
    }
  ]
}